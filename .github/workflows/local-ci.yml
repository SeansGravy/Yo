name: Yo Local CI Mirror

permissions:
  contents: write
  pull-requests: write

on:
  push:
    branches: [ main, feature/*, fix/* ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    name: Run pytest and Yo verify
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Configure Git for CI
        run: |
          git config --global user.name "codex-bot"
          git config --global user.email "codex@local"
          git config --global init.defaultBranch main
          git checkout main || git switch main
          git pull --rebase

      - name: Verify doc version
        run: |
          VERSION=$(git describe --tags --abbrev=0)
          grep -q "$VERSION" README.md || (echo "README does not contain version $VERSION" && exit 1)

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          python3 -m pip install -r requirements.txt
          if [ "$(uname)" = "Darwin" ]; then
            python3 -m pip install --break-system-packages -r requirements.txt
          fi

      - name: Run Yo CLI verify
        run: python3 -m yo.cli verify

      - name: Publish telemetry summary
        if: always()
        run: |
          python3 -m yo.cli explain verify || true
          ANALYTICS=$(python3 -m yo.cli telemetry analyze --json || echo "{}"); export ANALYTICS
          python3 - <<'PY'
import json
import os
from pathlib import Path

logs_dir = Path("data/logs")
summary_path = logs_dir / "test_summary.json"
history_path = logs_dir / "test_history.json"
analytics_env = os.environ.get("ANALYTICS", "{}")
try:
    analytics = json.loads(analytics_env)
except json.JSONDecodeError:
    analytics = {}

if not summary_path.exists():
    print("No test summary produced by verify.")
else:
    summary = json.loads(summary_path.read_text(encoding="utf-8"))
    lines = ["### Yo Validation Summary"]
    lines.append(f"- Status: {summary.get('status', 'unknown')}")
    lines.append(
        f"- Tests: {summary.get('tests_passed', 0)}/{summary.get('tests_total', 0)} passed"
    )
    duration = summary.get("duration_seconds")
    if duration is not None:
        lines.append(f"- Duration: {float(duration):.2f}s")
    pass_rate = summary.get("pass_rate")
    if isinstance(pass_rate, (int, float)):
        lines.append(f"- Pass rate: {pass_rate * 100:.1f}%")
    print("\n".join(lines))
    summary_file = os.environ.get("GITHUB_STEP_SUMMARY")
    if summary_file:
        with open(summary_file, "a", encoding="utf-8") as fh:
            fh.write("\n".join(lines) + "\n")

if history_path.exists():
    history = json.loads(history_path.read_text(encoding="utf-8"))
    print(f"Telemetry history entries: {len(history)}")

if analytics:
    summary_file = os.environ.get("GITHUB_STEP_SUMMARY")
    lines = ["", "### Yo Telemetry Insights"]
    mean_rate = analytics.get("pass_rate_mean")
    if isinstance(mean_rate, (int, float)):
        display_rate = mean_rate * 100 if mean_rate <= 1 else mean_rate
        lines.append(f"- Avg pass rate: {display_rate:.1f}%")
    volatility = analytics.get("pass_rate_volatility")
    if isinstance(volatility, (int, float)):
        lines.append(f"- Pass-rate volatility: {volatility:.3f}")
    duration = analytics.get("duration_average")
    if isinstance(duration, (int, float)):
        lines.append(f"- Avg duration: {duration:.2f}s")
    if summary_file and len(lines) > 2:
        with open(summary_file, "a", encoding="utf-8") as fh:
            fh.write("\n".join(lines) + "\n")
PY

      - name: Yo Audit Report
        if: always()
        run: |
          python3 -m yo.cli report audit
          export YO_HEALTH_SCORE=$(python3 -m yo.cli health report --json | jq -r '.health_score // .score // 0')
          if [ -z "$YO_HEALTH_SCORE" ] || [ "$YO_HEALTH_SCORE" = "null" ]; then
            YO_HEALTH_SCORE=0
            export YO_HEALTH_SCORE
          fi
          echo "YO_HEALTH_SCORE=${YO_HEALTH_SCORE}" >> $GITHUB_ENV
          python3 - <<'PY'
import json
import os
from pathlib import Path

audit_path = Path("data/logs/audit_report.json")
if audit_path.exists():
    try:
        audit = json.loads(audit_path.read_text(encoding="utf-8"))
    except json.JSONDecodeError:
        audit = {}
    summary_file = os.environ.get("GITHUB_STEP_SUMMARY")
    health_score = os.environ.get("YO_HEALTH_SCORE", "n/a")
    if summary_file:
        lines = ["### Yo Audit Overview"]
        health = audit.get("health", {})
        score = health.get("score", "n/a")
        lines.append(f"- Health score: {score}")
        lines.append(f"- Latest verify status: {health.get('latest_status', 'unknown')}")
        namespaces = audit.get("namespaces", [])
        lines.append(f"- Namespaces tracked: {len(namespaces)}")
        dep_events = audit.get("dependency_events", [])
        lines.append(f"- Recent dependency events: {len(dep_events)}")
        with open(summary_file, "a", encoding="utf-8") as fh:
            fh.write("\n".join(lines) + "\n")
PY

      - name: Sync documentation with latest release
        if: ${{ success() }}
        run: |
          VERSION=$(git describe --tags --abbrev=0)
          sed -i "s/^\*\*Current Release:.*$/\*\*Current Release:\*\* ${VERSION}/" README.md
          python3 -m yo.cli report audit --json --md --html
          cp data/logs/audit_report.md docs/RELEASE_NOTES.md
          cp data/logs/audit_report.html docs/latest.html
          echo "YO_VERSION=${VERSION}" >> $GITHUB_ENV

      - name: Update CHANGELOG
        if: ${{ success() }}
        run: |
          VERSION=$(git describe --tags --abbrev=0)
          DATE=$(date +%Y-%m-%d)
          sed -i "2i## [${VERSION}] ‚Äì ${DATE}\n### Added\n- Auto-generated entry\n" docs/CHANGELOG.md

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: yo-test-results
          path: |
            data/logs/test_summary.json
            data/logs/test_history.json
            data/logs/dependency_history.json
            data/logs/telemetry_summary.json
            data/logs/badge.md
            data/logs/audit_report.json
            data/logs/audit_report.md
            data/logs/audit_report.html
            yo_test_results_*.log
            docs/CHANGELOG.md

      - name: Check artifact sizes
        if: ${{ success() }}
        run: |
          for f in data/logs/audit_report.md data/logs/test_summary.json docs/CHANGELOG.md; do
            if [ ! -f "$f" ]; then
              echo "‚ùå Missing $f"
              exit 1
            fi
            size=$(wc -c <"$f")
            if [ "$size" -le 200 ]; then
              echo "‚ùå $f appears too small ($size bytes)"
              exit 1
            fi
            echo "‚úÖ $f size OK ($size bytes)"
          done

      - name: Generate artifact checksums
        if: ${{ success() }}
        run: |
          mkdir -p data/logs/checksums
          find data/logs -type f \( -name '*.json' -o -name '*.md' -o -name '*.html' \) -exec shasum -a 256 {} \; > data/logs/checksums/artifact_hashes.txt
          echo "‚úÖ Generated artifact checksums:"
          cat data/logs/checksums/artifact_hashes.txt

      - name: Sign artifact checksums
        if: ${{ success() }}
        run: |
          if ! gpg --list-secret-keys --with-colons | grep -q "codex-ci@local"; then
            gpg --batch --quick-gen-key "Codex CI (auto) <codex-ci@local>" ed25519 sign 0
          fi
          gpg --batch --yes --armor --local-user "Codex CI (auto) <codex-ci@local>" \
            --output data/logs/checksums/artifact_hashes.sig \
            --detach-sig data/logs/checksums/artifact_hashes.txt
          gpg --armor --export "Codex CI (auto) <codex-ci@local>" > data/logs/checksums/artifact_signing_public.asc

      - name: Append verification ledger
        if: ${{ success() }}
        run: |
          mkdir -p data/logs
          VERSION=${YO_VERSION:-$(git describe --tags --abbrev=0)}
          COMMIT=$(git rev-parse HEAD)
          HEALTH=$(python3 -m yo.cli health report --json | jq -r '.health_score // .score')
          TS=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          echo "{\"timestamp\":\"$TS\",\"version\":\"$VERSION\",\"commit\":\"$COMMIT\",\"health\":$HEALTH,\"checksum_file\":\"data/logs/checksums/artifact_hashes.txt\",\"signature\":\"data/logs/checksums/artifact_hashes.sig\"}" >> data/logs/verification_ledger.jsonl

      - name: Generate manual push instructions
        if: ${{ success() }}
        run: |
          VERSION=${YO_VERSION:-$(git describe --tags --abbrev=0)}
          HEALTH=$(python3 -m yo.cli health report --json | jq -r '.health_score // .score')
          mkdir -p data/logs
          cat <<EOF > data/logs/push_instructions.txt
‚úÖ Verification PASSED (Health ${HEALTH})
To publish this build, run:
    git add -A
    git commit -m "release: ${VERSION} verified build"
    git push origin main
Checksums: data/logs/checksums/artifact_hashes.txt
Signature: data/logs/checksums/artifact_hashes.sig
EOF
          echo "### üì¶ Verification Summary" >> $GITHUB_STEP_SUMMARY
          echo "Release: ${VERSION}" >> $GITHUB_STEP_SUMMARY
          echo "Health Score: ${HEALTH}" >> $GITHUB_STEP_SUMMARY
          echo "Artifacts prepared: audit_report, checksums, signatures" >> $GITHUB_STEP_SUMMARY
          echo "Status: ‚è∏ Awaiting manual push" >> $GITHUB_STEP_SUMMARY

      - name: Verify publish artifacts present
        if: ${{ success() }}
        run: |
          for f in data/logs/push_instructions.txt data/logs/checksums/artifact_hashes.sig data/logs/checksums/artifact_signing_public.asc; do
            if [ ! -f "$f" ]; then
              echo "‚ùå Missing publish artifact: $f"
              exit 1
            fi
            size=$(wc -c <"$f")
            if [ "$size" -le 64 ]; then
              echo "‚ùå $f appears too small ($size bytes)"
              exit 1
            fi
            echo "‚úÖ $f present ($size bytes)"
          done

      - name: Verify signature on clone
        if: ${{ success() }}
        run: python3 -m yo.cli verify signature --json

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: yo-test-results
          path: |
            data/logs/test_summary.json
            data/logs/test_history.json
            data/logs/dependency_history.json
            data/logs/telemetry_summary.json
            data/logs/badge.md
            data/logs/audit_report.json
            data/logs/audit_report.md
            data/logs/audit_report.html
            data/logs/checksums/artifact_hashes.txt
            data/logs/checksums/artifact_hashes.sig
            data/logs/checksums/artifact_signing_public.asc
            data/logs/verification_ledger.jsonl
            data/logs/push_instructions.txt
            yo_test_results_*.log
            docs/CHANGELOG.md
